{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43142b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import clear_session\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0552308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Parameters\n",
    "num_of_classes = 54\n",
    "data_shape = (119,1)\n",
    "\n",
    "#MLP Parameters\n",
    "times_to_run = 10 #Number of times to run MLP model\n",
    "mlp_epochs = 40\n",
    "valid_split = 0.20\n",
    "\n",
    "#Random Seeds\n",
    "selection_seed = 150\n",
    "seed_multiplier = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32674be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1059, 531)\n",
      "-110.0\n",
      "(1059, 130)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        ...,\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110]], dtype=int64),\n",
       " array([ 0,  0,  0, ..., 53, 53, 53]),\n",
       " (1059, 119))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./data/00_sorted.csv\"\n",
    "train_df = pd.read_csv(path,header=0)\n",
    "print(train_df.shape)\n",
    "a = train_df.mean()\n",
    "print(a[\"WAP004\"])\n",
    "for i in train_df.columns[:520]:\n",
    "    if a[i]==-110:\n",
    "        del train_df[i]\n",
    "print(train_df.shape)\n",
    "train_df[\"REF\"] = pd.factorize(train_df[\"REF\"])[0].astype(int)#将标签映射到顺序数字上\n",
    "labels = train_df.REF.values\n",
    "features = train_df.drop(columns=['TIMESTAMP','PHONEID','USERID','RELATIVEPOSITION',\n",
    "                                'SPACEID','BUILDINGID','FLOOR','LATITUDE','LONGITUDE',\n",
    "                                'BF','REF']).values\n",
    "input_shape = features.shape[1:]\n",
    "features,labels,features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51cfdc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        ...,\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110]], dtype=int64),\n",
       " (847, 119),\n",
       " array([ 3, 13, 45, 14,  6, 22, 15, 10,  8, 29, 48, 26,  9, 36,  0, 19, 13,\n",
       "         5, 20, 44, 18, 44, 34, 17, 19,  4, 11, 45, 13, 51, 26, 22, 13, 53,\n",
       "        27, 32, 44, 25, 50, 46, 28, 19,  5, 32, 45, 49, 16,  8, 24,  9, 46,\n",
       "        39, 51, 13, 15, 42, 14, 34, 17, 12, 40, 42,  7,  4, 15, 40, 24, 37,\n",
       "        28,  6, 21, 37, 35, 16, 27, 27, 31, 50, 37, 52, 24, 41, 21, 42, 38,\n",
       "        35, 53, 31, 46, 29, 29, 47,  5, 26, 18, 12, 35, 22, 17, 20, 20, 23,\n",
       "         1, 41, 33, 42, 17,  5, 50, 25, 25, 13, 21, 21, 24, 17, 27, 12,  3,\n",
       "        18, 12, 24, 14, 38, 21, 45, 25, 25, 13,  8, 25, 25, 27, 23, 39,  7,\n",
       "        14, 50, 33,  4, 19, 33, 28, 46, 47, 26, 17, 22,  5, 51,  7, 52, 39,\n",
       "        24, 52, 34,  2, 21, 50, 28, 53, 45, 46, 10, 52, 17, 46, 27, 38, 51,\n",
       "        46,  6,  6, 26, 36, 32, 52, 41, 18,  6, 40, 16,  9, 42, 13, 31, 47,\n",
       "        32, 15, 40, 20,  8, 40, 51, 33, 20, 27, 13,  6, 15, 22,  1, 34,  4,\n",
       "        51, 26, 14, 25, 51, 14, 37, 16, 26, 46, 30, 33, 14, 49, 20, 34, 48,\n",
       "        22,  6, 19, 13,  6, 28, 33,  2, 41, 39, 21,  5,  4, 30, 13, 25, 16,\n",
       "        31, 13, 16, 39,  9,  7, 26,  1,  0, 24, 28, 46, 46,  4, 24, 45, 37,\n",
       "        16,  2, 47, 31, 34, 41, 25,  9, 21, 20, 34, 32,  4, 32,  3, 43, 49,\n",
       "        33, 44, 50, 24, 46, 48,  6, 51,  6,  9, 49, 45, 12, 20, 27, 20,  0,\n",
       "        10, 27,  3, 24, 37, 39, 30, 38, 29, 35, 13, 17, 47, 11, 53, 49,  2,\n",
       "        13, 23, 31, 50,  0, 16, 48,  9, 13, 36, 40, 10, 28, 49, 28,  7, 30,\n",
       "        17, 24, 30, 40, 32, 39, 37, 35, 30, 26, 25, 22,  4, 20, 50, 27, 15,\n",
       "        35, 13, 11, 15, 41, 14, 26, 32, 52, 48, 51, 45, 49, 51, 52, 21, 19,\n",
       "        53,  5, 46, 15, 53, 14,  7,  0, 37, 25, 45, 12, 32, 21, 35, 18,  4,\n",
       "        22,  4, 40, 45, 36, 47, 39, 11, 14,  0, 53,  4,  5, 25, 25, 35,  6,\n",
       "        36, 12, 37, 31, 46,  1, 28, 52, 35, 33,  0, 10, 20, 26, 26, 13, 20,\n",
       "         9,  4, 19, 32, 38, 14, 13, 28,  7, 40, 43,  5, 25, 30, 12, 51, 34,\n",
       "        40, 43, 31,  0, 29, 21, 15, 32, 48, 14, 30, 51,  0, 12, 45, 20, 26,\n",
       "        52, 40,  0, 20, 25, 18, 25, 17, 38, 42, 35, 30, 26, 33, 28, 27, 28,\n",
       "        32,  1, 36, 33, 25, 12, 47, 38, 39, 16,  8, 30, 38, 13, 21, 34, 44,\n",
       "         7, 34, 48, 11, 36, 52, 32, 24, 12, 33, 15, 29, 18, 13, 33, 46, 47,\n",
       "        31, 25, 33, 24,  9, 49,  4, 30, 11, 49, 24, 18, 43, 15, 13, 19, 47,\n",
       "        26, 41, 25,  6, 29, 10, 24,  9, 20,  7, 34, 44, 42, 29,  8, 11, 19,\n",
       "        38, 29, 16,  2, 47, 53,  7, 50, 45, 18, 21, 41, 29, 42, 53, 50, 49,\n",
       "         3, 27, 38, 51, 39, 30, 17, 47, 15,  6, 23, 14, 34, 22, 44, 40, 32,\n",
       "        52, 37, 27, 34, 13, 40,  5, 49, 19, 19, 50, 20, 39, 43,  1, 36, 53,\n",
       "        35, 16, 37, 31,  5, 49,  7, 23, 26, 37, 44, 41, 50, 22, 48, 31, 13,\n",
       "         5, 44, 44, 30,  2, 27, 46, 36, 41, 21, 18, 22, 49, 53,  0, 52, 44,\n",
       "        13, 11, 11, 42,  3, 15, 29, 12, 12, 53, 37, 41, 51,  0, 40, 42, 13,\n",
       "        34, 13, 38, 51, 26, 53, 40, 45, 47, 36, 29, 44, 44, 44, 48, 26, 25,\n",
       "        17, 20, 32,  8, 12,  4,  0, 31, 15, 23,  2, 36, 37,  0, 35,  0, 16,\n",
       "        38, 48, 26, 15, 26,  0, 22, 36,  5, 32, 22, 11, 33, 48,  6, 10, 43,\n",
       "        18, 34, 52, 42, 38,  7,  5, 47, 48, 51, 22, 16, 33, 19, 10, 41,  2,\n",
       "         8, 53, 16, 41, 52, 13, 15,  7, 39, 13, 34, 22, 53, 24, 19, 39, 16,\n",
       "        11, 20, 30, 20, 14,  9, 15, 37, 35, 40, 45, 11,  4, 49, 25, 31,  8,\n",
       "        14, 48, 12, 39, 23, 36, 14, 45, 52,  8, 48,  1, 42, 41, 36, 33,  1,\n",
       "        31,  8, 26, 13, 47, 27, 29, 12, 31, 12, 50, 27, 26, 29, 21, 42, 44,\n",
       "        18,  3, 26, 49, 36, 13, 49, 20, 50, 53, 12,  5, 13, 17, 41, 21, 11,\n",
       "        47, 12, 51, 28, 25,  6, 45, 31, 13, 19, 38, 17, 13, 50, 42, 28, 18,\n",
       "        29, 25,  8, 18,  7,  8, 43, 38, 12, 51, 13,  7, 19, 20, 46, 16, 41,\n",
       "        52, 47, 35, 44, 36, 26, 30, 50, 22, 43, 28, 29, 28, 18,  4,  6,  5,\n",
       "        30, 20, 42, 48,  3, 35, 39, 37, 38, 35, 17, 20, 42, 23]),\n",
       " (847,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, \n",
    "                                                    labels, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state= selection_seed,\n",
    "                                                    #random_state：可以理解为随机数种子，主要是为了复现结果而设置\n",
    "                                                    stratify=labels)#stratify保证测试集中，所有类别的齐全\n",
    "X_train,X_train.shape,Y_train,Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c55ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(847, 119)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "\n",
    "#将类别向量映射为二值类别矩阵, 用于应用到以categorical_crossentropy为目标函数的模型中.\n",
    "#to_categorical和pd.get_dummies推荐前者，后者原理更复杂\n",
    "Y_train_encoded = to_categorical(Y_train)\n",
    "Y_test_encoded = to_categorical(Y_test)\n",
    "scaler = StandardScaler()  #from sklearn.preprocessing import StandardScaler\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "X_test_transformed = scaler.fit_transform(X_test)\n",
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994401a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xfp\\AppData\\Local\\Temp\\ipykernel_14124\\3108810693.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(times_to_run)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32897ce30806478eb217c2caa54003c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Test acc: 0.75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inp,output)\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(\u001b[38;5;241m0.0002\u001b[39m, \u001b[38;5;241m0.5\u001b[39m),\u001b[38;5;66;03m#learning rate, the exponential decay rate for the 1st moment estimates\u001b[39;00m\n\u001b[0;32m     20\u001b[0m                                           \u001b[38;5;66;03m# 学习率      , 一阶矩估计的指数衰减率\u001b[39;00m\n\u001b[0;32m     21\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 24\u001b[0m history_temp \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mY_train_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlp_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m history\u001b[38;5;241m.\u001b[39mappend(history_temp)\n\u001b[0;32m     31\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_transformed, \n\u001b[0;32m     32\u001b[0m                                      Y_test_encoded, \n\u001b[0;32m     33\u001b[0m                                      verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_test_loss =[]\n",
    "all_test_acc = []\n",
    "history = []\n",
    "\n",
    "for i in tqdm_notebook(range(times_to_run)):\n",
    "    seed(i*seed_multiplier)#操作级\n",
    "    tf.random.set_seed(i*seed_multiplier)#图级\n",
    "    inp = Input(shape=input_shape,name='ap_features')\n",
    "    x = Dense(1024,activation=LeakyReLU(alpha=0))(inp)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(512,activation=LeakyReLU(alpha=0))(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(256,activation=LeakyReLU(alpha=0))(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128,activation=LeakyReLU(alpha=0))(x)\n",
    "    output = Dense(54,activation='softmax')(x)\n",
    "    model = Model(inp,output)\n",
    "\n",
    "    model.compile(optimizer=Adam(0.0002, 0.5),#learning rate, the exponential decay rate for the 1st moment estimates\n",
    "                                              # 学习率      , 一阶矩估计的指数衰减率\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history_temp = model.fit(X_train_transformed,\n",
    "                            Y_train_encoded,\n",
    "                            epochs=mlp_epochs,\n",
    "                            batch_size=32,\n",
    "                            validation_split=valid_split,\n",
    "                            verbose=0)\n",
    "    history.append(history_temp)\n",
    "    test_loss, test_acc = model.evaluate(X_test_transformed, \n",
    "                                         Y_test_encoded, \n",
    "                                         verbose=0)\n",
    "    print(\"#{} Test acc:\".format(i), test_acc)\n",
    "\n",
    "    all_test_acc.append(test_acc)\n",
    "    all_test_loss.append(test_loss)\n",
    "    del(model)\n",
    "    clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da646a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainacc = []\n",
    "trainloss = []\n",
    "valacc = []\n",
    "valloss = []\n",
    "for i in range (len(history)):\n",
    "    trainacc.append(history[i].history['accuracy'])\n",
    "    trainloss.append(history[i].history['loss'])\n",
    "    valacc.append(history[i].history['val_accuracy'])\n",
    "    valloss.append(history[i].history['val_loss'])\n",
    "\n",
    "acc = np.mean(trainacc, axis=0)\n",
    "val_acc = np.mean(valacc, axis=0)\n",
    "loss = np.mean(trainloss, axis=0)\n",
    "val_loss = np.mean(valloss, axis=0)\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()#作用是加上图例，很有必要\n",
    "plt.savefig(\"./real/real_TRandVAL_acc.png\")\n",
    "plt.figure()#创建新图\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"./real/real_TRandVAL_loss.png\")\n",
    "test_loss = np.mean(all_test_loss, axis=0)\n",
    "test_acc = np.mean(all_test_acc, axis=0)\n",
    "test_loss,test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
