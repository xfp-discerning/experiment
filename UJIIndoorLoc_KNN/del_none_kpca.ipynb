{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15b776b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, LeakyReLU\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df9fd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1059, 531)\n",
      "(1059, 130)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        ...,\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110]], dtype=int64),\n",
       " array([ 0,  0,  0, ..., 53, 53, 53]),\n",
       " (1059, 119))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./UJIIndoorLoc/children_13/sorted/00_sorted.csv\"\n",
    "train_df = pd.read_csv(path,header=0)\n",
    "print(train_df.shape)\n",
    "a = train_df.mean()\n",
    "for i in train_df.columns[:520]:\n",
    "    if a[i]==-110:\n",
    "        del train_df[i]\n",
    "print(train_df.shape)\n",
    "train_df[\"REF\"] = pd.factorize(train_df[\"REF\"])[0].astype(int)#将标签映射到顺序数字上\n",
    "labels = train_df.REF.values\n",
    "features = train_df.drop(columns=['TIMESTAMP','PHONEID','USERID','RELATIVEPOSITION',\n",
    "                                'SPACEID','BUILDINGID','FLOOR','LATITUDE','LONGITUDE',\n",
    "                                'BF','REF']).values\n",
    "features,labels,features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced87f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, \n",
    "                                                    labels, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state= 150,\n",
    "                                                    #random_state：可以理解为随机数种子，主要是为了复现结果而设置\n",
    "                                                    stratify=labels)\n",
    "X_train,Y_train = shuffle(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2d4546",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler().fit(X_train)\n",
    "X_train_transform = scale.transform(X_train)\n",
    "X_test_transform = scale.transform(X_test)\n",
    "Y_train_encoded = to_categorical(Y_train)\n",
    "Y_test_encoded = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "712a64b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-4.34535880e-01, -4.60094318e-02,  2.27848448e-01, ...,\n",
       "         -1.60244339e-02, -9.80403083e-03,  7.17231004e-03],\n",
       "        [-4.26721293e-01, -1.73598267e-01, -2.26627874e-01, ...,\n",
       "          4.48780299e-02, -3.72480244e-02, -4.53463804e-02],\n",
       "        [-7.14256665e-01, -1.40135691e-01,  3.05642139e-01, ...,\n",
       "          2.31420585e-02,  7.35797572e-03, -1.33659276e-02],\n",
       "        ...,\n",
       "        [ 4.21523484e-01, -3.41372192e-02, -5.47472967e-02, ...,\n",
       "          2.36029902e-03, -4.73378493e-03, -3.91495760e-04],\n",
       "        [ 3.73970629e-01,  1.02227364e-01,  8.38252695e-02, ...,\n",
       "          4.77197397e-04,  2.22933531e-02,  4.77803264e-03],\n",
       "        [ 6.49708293e-01,  2.84623747e-01, -5.82309744e-02, ...,\n",
       "         -2.58836071e-02,  1.32880055e-02, -1.00329626e-02]]),\n",
       " array([[-4.24684889e-01, -5.85445519e-02, -8.36540411e-02, ...,\n",
       "          8.12490341e-03, -9.74926754e-03,  7.10114976e-03],\n",
       "        [-7.68971887e-01,  3.14778465e-01,  1.32664290e-01, ...,\n",
       "         -4.08508569e-02, -1.05656496e-02,  3.32642011e-02],\n",
       "        [-5.57034707e-01, -3.69228643e-02,  1.94612101e-02, ...,\n",
       "          1.81885684e-03, -1.64754898e-03, -1.44475398e-03],\n",
       "        ...,\n",
       "        [-3.45073242e-01, -2.69151817e-01, -5.14368826e-02, ...,\n",
       "          1.58698327e-02,  1.19639982e-02, -2.62539524e-02],\n",
       "        [-8.19754802e-01,  6.29041043e-01,  2.53793379e-01, ...,\n",
       "         -5.43226230e-03, -2.11664043e-02,  1.18531372e-02],\n",
       "        [ 6.28287815e-01, -3.20375277e-01,  3.62977878e-01, ...,\n",
       "         -5.39820894e-04, -1.56879138e-02,  1.00076493e-02]]),\n",
       " (741, 100),\n",
       " (318, 100))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_pca=KernelPCA(n_components = 100,kernel='sigmoid',gamma=0.041111).fit(X_train_transform)\n",
    "X_train_pca = rbf_pca.transform(X_train_transform)\n",
    "X_test_pca = rbf_pca.transform(X_test_transform)\n",
    "X_train_pca,X_test_pca,X_train_pca.shape,X_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdacdf32",
   "metadata": {},
   "source": [
    "### 找出kpca最合适的kernel和gama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d18bb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\xfp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('kpca', KernelPCA(n_components=2)),\n",
       "                                       ('log_reg', LogisticRegression())]),\n",
       "             param_grid=[{'kpca__gamma': array([0.01      , 0.01444444, 0.01888889, 0.02333333, 0.02777778,\n",
       "       0.03222222, 0.03666667, 0.04111111, 0.04555556, 0.05      ]),\n",
       "                          'kpca__kernel': ['rbf', 'sigmoid', 'cosine',\n",
       "                                           'poly']}])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.pipeline import Pipeline\n",
    "clf = Pipeline([\n",
    "        (\"kpca\", KernelPCA(n_components=2)),\n",
    "        (\"log_reg\", LogisticRegression())\n",
    "])\n",
    "param_grid = [{\n",
    "        \"kpca__gamma\": np.linspace(0.01, 0.05,10),\n",
    "        \"kpca__kernel\": [\"rbf\", \"sigmoid\",\"cosine\",\"poly\"]#不能加上\"precomputed\"，不然会报错 error: X should be a square kernel matrix\n",
    "    }]\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
    "grid_search.fit(X_train_transform, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec13b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kpca__gamma': 0.04111111111111111, 'kpca__kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2be5c8",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "639038be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "19/19 [==============================] - 1s 12ms/step - loss: 3.9842 - accuracy: 0.0439 - val_loss: 3.9752 - val_accuracy: 0.0537\n",
      "Epoch 2/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.9663 - accuracy: 0.0861 - val_loss: 3.9632 - val_accuracy: 0.0805\n",
      "Epoch 3/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.9460 - accuracy: 0.1064 - val_loss: 3.9477 - val_accuracy: 0.0738\n",
      "Epoch 4/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.9183 - accuracy: 0.1166 - val_loss: 3.9246 - val_accuracy: 0.0872\n",
      "Epoch 5/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.8801 - accuracy: 0.1301 - val_loss: 3.8907 - val_accuracy: 0.0805\n",
      "Epoch 6/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.8261 - accuracy: 0.1385 - val_loss: 3.8411 - val_accuracy: 0.0805\n",
      "Epoch 7/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.7508 - accuracy: 0.1132 - val_loss: 3.7732 - val_accuracy: 0.0604\n",
      "Epoch 8/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.6542 - accuracy: 0.1064 - val_loss: 3.6886 - val_accuracy: 0.0537\n",
      "Epoch 9/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.5457 - accuracy: 0.1030 - val_loss: 3.5965 - val_accuracy: 0.0403\n",
      "Epoch 10/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.4344 - accuracy: 0.1081 - val_loss: 3.5084 - val_accuracy: 0.0604\n",
      "Epoch 11/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.3330 - accuracy: 0.1537 - val_loss: 3.4269 - val_accuracy: 0.1007\n",
      "Epoch 12/250\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3.2402 - accuracy: 0.1926 - val_loss: 3.3471 - val_accuracy: 0.1342\n",
      "Epoch 13/250\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3.1519 - accuracy: 0.2078 - val_loss: 3.2661 - val_accuracy: 0.1544\n",
      "Epoch 14/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.0671 - accuracy: 0.2331 - val_loss: 3.1929 - val_accuracy: 0.1879\n",
      "Epoch 15/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.9808 - accuracy: 0.2703 - val_loss: 3.1176 - val_accuracy: 0.1812\n",
      "Epoch 16/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.8949 - accuracy: 0.2889 - val_loss: 3.0403 - val_accuracy: 0.2148\n",
      "Epoch 17/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.8063 - accuracy: 0.3361 - val_loss: 2.9572 - val_accuracy: 0.2282\n",
      "Epoch 18/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.7174 - accuracy: 0.3682 - val_loss: 2.8776 - val_accuracy: 0.2416\n",
      "Epoch 19/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.6284 - accuracy: 0.3885 - val_loss: 2.7985 - val_accuracy: 0.2483\n",
      "Epoch 20/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5435 - accuracy: 0.3936 - val_loss: 2.7147 - val_accuracy: 0.2550\n",
      "Epoch 21/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.4554 - accuracy: 0.4341 - val_loss: 2.6358 - val_accuracy: 0.2617\n",
      "Epoch 22/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3706 - accuracy: 0.4172 - val_loss: 2.5599 - val_accuracy: 0.2483\n",
      "Epoch 23/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2898 - accuracy: 0.4645 - val_loss: 2.4954 - val_accuracy: 0.2617\n",
      "Epoch 24/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2093 - accuracy: 0.4544 - val_loss: 2.4241 - val_accuracy: 0.2617\n",
      "Epoch 25/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.1395 - accuracy: 0.4831 - val_loss: 2.3577 - val_accuracy: 0.2953\n",
      "Epoch 26/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0629 - accuracy: 0.5000 - val_loss: 2.2920 - val_accuracy: 0.3020\n",
      "Epoch 27/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.9934 - accuracy: 0.5186 - val_loss: 2.2349 - val_accuracy: 0.3221\n",
      "Epoch 28/250\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.9275 - accuracy: 0.5203 - val_loss: 2.1820 - val_accuracy: 0.3490\n",
      "Epoch 29/250\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.8622 - accuracy: 0.5608 - val_loss: 2.1358 - val_accuracy: 0.3557\n",
      "Epoch 30/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7994 - accuracy: 0.5608 - val_loss: 2.0727 - val_accuracy: 0.3691\n",
      "Epoch 31/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.7441 - accuracy: 0.5591 - val_loss: 2.0458 - val_accuracy: 0.3624\n",
      "Epoch 32/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.6890 - accuracy: 0.5878 - val_loss: 1.9925 - val_accuracy: 0.3624\n",
      "Epoch 33/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6354 - accuracy: 0.5997 - val_loss: 1.9485 - val_accuracy: 0.3624\n",
      "Epoch 34/250\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.5865 - accuracy: 0.6081 - val_loss: 1.9132 - val_accuracy: 0.3758\n",
      "Epoch 35/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5395 - accuracy: 0.6318 - val_loss: 1.8768 - val_accuracy: 0.4362\n",
      "Epoch 36/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.4946 - accuracy: 0.6639 - val_loss: 1.8500 - val_accuracy: 0.4631\n",
      "Epoch 37/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.4532 - accuracy: 0.6639 - val_loss: 1.8090 - val_accuracy: 0.4564\n",
      "Epoch 38/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.4102 - accuracy: 0.6824 - val_loss: 1.7846 - val_accuracy: 0.4228\n",
      "Epoch 39/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.3711 - accuracy: 0.6892 - val_loss: 1.7715 - val_accuracy: 0.4899\n",
      "Epoch 40/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.3325 - accuracy: 0.7010 - val_loss: 1.7547 - val_accuracy: 0.4564\n",
      "Epoch 41/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.3041 - accuracy: 0.6841 - val_loss: 1.7002 - val_accuracy: 0.4832\n",
      "Epoch 42/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.2668 - accuracy: 0.6976 - val_loss: 1.6823 - val_accuracy: 0.4832\n",
      "Epoch 43/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.2356 - accuracy: 0.7010 - val_loss: 1.6427 - val_accuracy: 0.4966\n",
      "Epoch 44/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.2082 - accuracy: 0.7145 - val_loss: 1.6390 - val_accuracy: 0.5235\n",
      "Epoch 45/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.1785 - accuracy: 0.7213 - val_loss: 1.6301 - val_accuracy: 0.5101\n",
      "Epoch 46/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1501 - accuracy: 0.7297 - val_loss: 1.6124 - val_accuracy: 0.5168\n",
      "Epoch 47/250\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.1297 - accuracy: 0.7162 - val_loss: 1.5907 - val_accuracy: 0.5168\n",
      "Epoch 48/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1000 - accuracy: 0.7264 - val_loss: 1.5944 - val_accuracy: 0.5034\n",
      "Epoch 49/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0779 - accuracy: 0.7348 - val_loss: 1.5677 - val_accuracy: 0.5034\n",
      "Epoch 50/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0537 - accuracy: 0.7517 - val_loss: 1.5609 - val_accuracy: 0.5034\n",
      "Epoch 51/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0319 - accuracy: 0.7365 - val_loss: 1.5569 - val_accuracy: 0.5235\n",
      "Epoch 52/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0110 - accuracy: 0.7517 - val_loss: 1.5527 - val_accuracy: 0.5034\n",
      "Epoch 53/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9907 - accuracy: 0.7534 - val_loss: 1.5269 - val_accuracy: 0.5302\n",
      "Epoch 54/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9730 - accuracy: 0.7635 - val_loss: 1.5085 - val_accuracy: 0.5570\n",
      "Epoch 55/250\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.9525 - accuracy: 0.7703 - val_loss: 1.5136 - val_accuracy: 0.5235\n",
      "Epoch 56/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9396 - accuracy: 0.7669 - val_loss: 1.4887 - val_accuracy: 0.5570\n",
      "Epoch 57/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9194 - accuracy: 0.7686 - val_loss: 1.4903 - val_accuracy: 0.5570\n",
      "Epoch 58/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9004 - accuracy: 0.7669 - val_loss: 1.4890 - val_accuracy: 0.5302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8906 - accuracy: 0.7770 - val_loss: 1.4821 - val_accuracy: 0.5302\n",
      "Epoch 60/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8714 - accuracy: 0.7686 - val_loss: 1.4762 - val_accuracy: 0.5436\n",
      "Epoch 61/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8598 - accuracy: 0.7787 - val_loss: 1.4596 - val_accuracy: 0.5369\n",
      "Epoch 62/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8392 - accuracy: 0.7838 - val_loss: 1.4628 - val_accuracy: 0.5302\n",
      "Epoch 63/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8285 - accuracy: 0.7855 - val_loss: 1.4542 - val_accuracy: 0.5503\n",
      "Epoch 64/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8115 - accuracy: 0.7905 - val_loss: 1.4549 - val_accuracy: 0.5369\n",
      "Epoch 65/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7996 - accuracy: 0.8007 - val_loss: 1.4444 - val_accuracy: 0.5302\n",
      "Epoch 66/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7882 - accuracy: 0.7905 - val_loss: 1.4364 - val_accuracy: 0.5705\n",
      "Epoch 67/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7776 - accuracy: 0.7956 - val_loss: 1.4764 - val_accuracy: 0.5503\n",
      "Epoch 68/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7631 - accuracy: 0.7973 - val_loss: 1.4558 - val_accuracy: 0.5369\n",
      "Epoch 69/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7506 - accuracy: 0.7956 - val_loss: 1.4539 - val_accuracy: 0.5369\n",
      "Epoch 70/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7384 - accuracy: 0.8074 - val_loss: 1.4365 - val_accuracy: 0.5839\n",
      "Epoch 71/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7303 - accuracy: 0.8041 - val_loss: 1.4336 - val_accuracy: 0.5705\n",
      "Epoch 72/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7235 - accuracy: 0.7990 - val_loss: 1.4374 - val_accuracy: 0.5503\n",
      "Epoch 73/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7085 - accuracy: 0.8176 - val_loss: 1.4235 - val_accuracy: 0.5772\n",
      "Epoch 74/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6988 - accuracy: 0.8041 - val_loss: 1.4208 - val_accuracy: 0.5705\n",
      "Epoch 75/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.8142 - val_loss: 1.4172 - val_accuracy: 0.5638\n",
      "Epoch 76/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.8159 - val_loss: 1.4361 - val_accuracy: 0.5570\n",
      "Epoch 77/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6690 - accuracy: 0.8226 - val_loss: 1.4310 - val_accuracy: 0.5705\n",
      "Epoch 78/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.8176 - val_loss: 1.4204 - val_accuracy: 0.5638\n",
      "Epoch 79/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.8294 - val_loss: 1.4224 - val_accuracy: 0.5638\n",
      "Epoch 80/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.8294 - val_loss: 1.4252 - val_accuracy: 0.5973\n",
      "Epoch 81/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.8294 - val_loss: 1.4161 - val_accuracy: 0.5839\n",
      "Epoch 82/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.8243 - val_loss: 1.4294 - val_accuracy: 0.5705\n",
      "Epoch 83/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.8193 - val_loss: 1.4215 - val_accuracy: 0.5638\n",
      "Epoch 84/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.8395 - val_loss: 1.4137 - val_accuracy: 0.5705\n",
      "Epoch 85/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.8294 - val_loss: 1.4330 - val_accuracy: 0.5772\n",
      "Epoch 86/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.8446 - val_loss: 1.4277 - val_accuracy: 0.5772\n",
      "Epoch 87/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.8497 - val_loss: 1.4181 - val_accuracy: 0.5772\n",
      "Epoch 88/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.8514 - val_loss: 1.4132 - val_accuracy: 0.5638\n",
      "Epoch 89/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.8530 - val_loss: 1.4125 - val_accuracy: 0.5772\n",
      "Epoch 90/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.8412 - val_loss: 1.4435 - val_accuracy: 0.5436\n",
      "Epoch 91/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.8547 - val_loss: 1.4254 - val_accuracy: 0.5570\n",
      "Epoch 92/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5541 - accuracy: 0.8564 - val_loss: 1.4197 - val_accuracy: 0.5638\n",
      "Epoch 93/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.8581 - val_loss: 1.4122 - val_accuracy: 0.5772\n",
      "Epoch 94/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.8514 - val_loss: 1.4163 - val_accuracy: 0.5772\n",
      "Epoch 95/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.8581 - val_loss: 1.4470 - val_accuracy: 0.5570\n",
      "Epoch 96/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.8632 - val_loss: 1.4363 - val_accuracy: 0.5772\n",
      "Epoch 97/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.8564 - val_loss: 1.4259 - val_accuracy: 0.5705\n",
      "Epoch 98/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.8733 - val_loss: 1.4162 - val_accuracy: 0.5705\n",
      "Epoch 99/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5081 - accuracy: 0.8716 - val_loss: 1.4386 - val_accuracy: 0.5839\n",
      "Epoch 100/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.8615 - val_loss: 1.4333 - val_accuracy: 0.5705\n",
      "Epoch 101/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.8581 - val_loss: 1.4197 - val_accuracy: 0.5839\n",
      "Epoch 102/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.8750 - val_loss: 1.4434 - val_accuracy: 0.5705\n",
      "Epoch 103/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.8716 - val_loss: 1.4256 - val_accuracy: 0.5772\n",
      "Epoch 104/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.8632 - val_loss: 1.4267 - val_accuracy: 0.5705\n",
      "Epoch 105/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.8818 - val_loss: 1.4339 - val_accuracy: 0.5906\n",
      "Epoch 106/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.8716 - val_loss: 1.4260 - val_accuracy: 0.5705\n",
      "Epoch 107/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.8851 - val_loss: 1.4447 - val_accuracy: 0.5638\n",
      "Epoch 108/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.8801 - val_loss: 1.4598 - val_accuracy: 0.5436\n",
      "Epoch 109/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.8868 - val_loss: 1.4276 - val_accuracy: 0.5772\n",
      "Epoch 110/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.8818 - val_loss: 1.4209 - val_accuracy: 0.5906\n",
      "Epoch 111/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.8868 - val_loss: 1.4288 - val_accuracy: 0.5705\n",
      "Epoch 112/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.9037 - val_loss: 1.4265 - val_accuracy: 0.5570\n",
      "Epoch 113/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8919 - val_loss: 1.4278 - val_accuracy: 0.5772\n",
      "Epoch 114/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8986 - val_loss: 1.4420 - val_accuracy: 0.5705\n",
      "Epoch 115/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8936 - val_loss: 1.4419 - val_accuracy: 0.5638\n",
      "Epoch 116/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8851 - val_loss: 1.4399 - val_accuracy: 0.5638\n",
      "Epoch 117/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8919 - val_loss: 1.4619 - val_accuracy: 0.5705\n",
      "Epoch 118/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8936 - val_loss: 1.4696 - val_accuracy: 0.5570\n",
      "Epoch 119/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8986 - val_loss: 1.4518 - val_accuracy: 0.5772\n",
      "Epoch 120/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8902 - val_loss: 1.4353 - val_accuracy: 0.5906\n",
      "Epoch 121/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8936 - val_loss: 1.4602 - val_accuracy: 0.5772\n",
      "Epoch 122/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.9003 - val_loss: 1.4393 - val_accuracy: 0.5839\n",
      "Epoch 123/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.9088 - val_loss: 1.4451 - val_accuracy: 0.5906\n",
      "Epoch 124/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.9105 - val_loss: 1.4787 - val_accuracy: 0.5705\n",
      "Epoch 125/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.9020 - val_loss: 1.4484 - val_accuracy: 0.5705\n",
      "Epoch 126/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.9003 - val_loss: 1.4530 - val_accuracy: 0.5705\n",
      "Epoch 127/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.9054 - val_loss: 1.4664 - val_accuracy: 0.5772\n",
      "Epoch 128/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.9037 - val_loss: 1.4498 - val_accuracy: 0.5906\n",
      "Epoch 129/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.9088 - val_loss: 1.4834 - val_accuracy: 0.5973\n",
      "Epoch 130/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.9139 - val_loss: 1.4849 - val_accuracy: 0.5772\n",
      "Epoch 131/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.9105 - val_loss: 1.4805 - val_accuracy: 0.5772\n",
      "Epoch 132/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3620 - accuracy: 0.9122 - val_loss: 1.4857 - val_accuracy: 0.5705\n",
      "Epoch 133/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.9122 - val_loss: 1.4741 - val_accuracy: 0.5772\n",
      "Epoch 134/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.9071 - val_loss: 1.4636 - val_accuracy: 0.5772\n",
      "Epoch 135/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.9172 - val_loss: 1.4803 - val_accuracy: 0.5839\n",
      "Epoch 136/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.9172 - val_loss: 1.4959 - val_accuracy: 0.5906\n",
      "Epoch 137/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.9172 - val_loss: 1.4900 - val_accuracy: 0.5906\n",
      "Epoch 138/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.9206 - val_loss: 1.4846 - val_accuracy: 0.5839\n",
      "Epoch 139/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.9206 - val_loss: 1.5124 - val_accuracy: 0.5705\n",
      "Epoch 140/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.9139 - val_loss: 1.4905 - val_accuracy: 0.5906\n",
      "Epoch 141/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.9240 - val_loss: 1.5010 - val_accuracy: 0.5839\n",
      "Epoch 142/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.9172 - val_loss: 1.4938 - val_accuracy: 0.5839\n",
      "Epoch 143/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.9139 - val_loss: 1.5258 - val_accuracy: 0.5839\n",
      "Epoch 144/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.9257 - val_loss: 1.5084 - val_accuracy: 0.5906\n",
      "Epoch 145/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.9324 - val_loss: 1.4915 - val_accuracy: 0.5705\n",
      "Epoch 146/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.9341 - val_loss: 1.5320 - val_accuracy: 0.5772\n",
      "Epoch 147/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3157 - accuracy: 0.9240 - val_loss: 1.5068 - val_accuracy: 0.5839\n",
      "Epoch 148/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3132 - accuracy: 0.9307 - val_loss: 1.5206 - val_accuracy: 0.5705\n",
      "Epoch 149/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.9206 - val_loss: 1.5198 - val_accuracy: 0.5705\n",
      "Epoch 150/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3002 - accuracy: 0.9324 - val_loss: 1.5406 - val_accuracy: 0.5638\n",
      "Epoch 151/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3005 - accuracy: 0.9240 - val_loss: 1.5234 - val_accuracy: 0.5906\n",
      "Epoch 152/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2989 - accuracy: 0.9307 - val_loss: 1.5174 - val_accuracy: 0.5839\n",
      "Epoch 153/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.9307 - val_loss: 1.5436 - val_accuracy: 0.5906\n",
      "Epoch 154/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.9375 - val_loss: 1.5311 - val_accuracy: 0.5906\n",
      "Epoch 155/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.9291 - val_loss: 1.5437 - val_accuracy: 0.5705\n",
      "Epoch 156/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2862 - accuracy: 0.9324 - val_loss: 1.5387 - val_accuracy: 0.5839\n",
      "Epoch 157/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2852 - accuracy: 0.9392 - val_loss: 1.5360 - val_accuracy: 0.5705\n",
      "Epoch 158/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2822 - accuracy: 0.9291 - val_loss: 1.5477 - val_accuracy: 0.5973\n",
      "Epoch 159/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2808 - accuracy: 0.9274 - val_loss: 1.5280 - val_accuracy: 0.5705\n",
      "Epoch 160/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2774 - accuracy: 0.9358 - val_loss: 1.5459 - val_accuracy: 0.5839\n",
      "Epoch 161/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2745 - accuracy: 0.9392 - val_loss: 1.5410 - val_accuracy: 0.5839\n",
      "Epoch 162/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.9358 - val_loss: 1.5574 - val_accuracy: 0.5839\n",
      "Epoch 163/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2699 - accuracy: 0.9341 - val_loss: 1.5752 - val_accuracy: 0.5906\n",
      "Epoch 164/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.9443 - val_loss: 1.5651 - val_accuracy: 0.5839\n",
      "Epoch 165/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2644 - accuracy: 0.9510 - val_loss: 1.5709 - val_accuracy: 0.5705\n",
      "Epoch 166/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.9409 - val_loss: 1.5602 - val_accuracy: 0.5772\n",
      "Epoch 167/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.9375 - val_loss: 1.5721 - val_accuracy: 0.5839\n",
      "Epoch 168/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2563 - accuracy: 0.9409 - val_loss: 1.5830 - val_accuracy: 0.5839\n",
      "Epoch 169/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2553 - accuracy: 0.9409 - val_loss: 1.5973 - val_accuracy: 0.5906\n",
      "Epoch 170/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.9510 - val_loss: 1.5801 - val_accuracy: 0.5839\n",
      "Epoch 171/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2528 - accuracy: 0.9392 - val_loss: 1.5958 - val_accuracy: 0.5705\n",
      "Epoch 172/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.9476 - val_loss: 1.5891 - val_accuracy: 0.5839\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.9392 - val_loss: 1.6029 - val_accuracy: 0.5638\n",
      "Epoch 174/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2444 - accuracy: 0.9443 - val_loss: 1.5879 - val_accuracy: 0.5772\n",
      "Epoch 175/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2400 - accuracy: 0.9459 - val_loss: 1.5855 - val_accuracy: 0.5772\n",
      "Epoch 176/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2394 - accuracy: 0.9544 - val_loss: 1.6032 - val_accuracy: 0.5705\n",
      "Epoch 177/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2382 - accuracy: 0.9476 - val_loss: 1.6129 - val_accuracy: 0.5839\n",
      "Epoch 178/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2341 - accuracy: 0.9544 - val_loss: 1.6195 - val_accuracy: 0.5839\n",
      "Epoch 179/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2346 - accuracy: 0.9493 - val_loss: 1.6191 - val_accuracy: 0.5638\n",
      "Epoch 180/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2298 - accuracy: 0.9527 - val_loss: 1.6174 - val_accuracy: 0.5772\n",
      "Epoch 181/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.9527 - val_loss: 1.6208 - val_accuracy: 0.5839\n",
      "Epoch 182/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2263 - accuracy: 0.9493 - val_loss: 1.6147 - val_accuracy: 0.5772\n",
      "Epoch 183/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9561 - val_loss: 1.6197 - val_accuracy: 0.5772\n",
      "Epoch 184/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2239 - accuracy: 0.9578 - val_loss: 1.6167 - val_accuracy: 0.5839\n",
      "Epoch 185/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2200 - accuracy: 0.9561 - val_loss: 1.6326 - val_accuracy: 0.5772\n",
      "Epoch 186/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9510 - val_loss: 1.6382 - val_accuracy: 0.5772\n",
      "Epoch 187/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2188 - accuracy: 0.9595 - val_loss: 1.6630 - val_accuracy: 0.5772\n",
      "Epoch 188/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2147 - accuracy: 0.9527 - val_loss: 1.6197 - val_accuracy: 0.5839\n",
      "Epoch 189/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.9527 - val_loss: 1.6671 - val_accuracy: 0.5906\n",
      "Epoch 190/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2113 - accuracy: 0.9544 - val_loss: 1.6468 - val_accuracy: 0.5772\n",
      "Epoch 191/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2082 - accuracy: 0.9527 - val_loss: 1.6429 - val_accuracy: 0.5906\n",
      "Epoch 192/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2079 - accuracy: 0.9611 - val_loss: 1.6531 - val_accuracy: 0.5839\n",
      "Epoch 193/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2058 - accuracy: 0.9544 - val_loss: 1.6481 - val_accuracy: 0.5839\n",
      "Epoch 194/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2029 - accuracy: 0.9611 - val_loss: 1.6791 - val_accuracy: 0.5906\n",
      "Epoch 195/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1992 - accuracy: 0.9578 - val_loss: 1.6573 - val_accuracy: 0.5839\n",
      "Epoch 196/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.9578 - val_loss: 1.6834 - val_accuracy: 0.5839\n",
      "Epoch 197/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1996 - accuracy: 0.9611 - val_loss: 1.6900 - val_accuracy: 0.5906\n",
      "Epoch 198/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1961 - accuracy: 0.9611 - val_loss: 1.6819 - val_accuracy: 0.5839\n",
      "Epoch 199/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1944 - accuracy: 0.9611 - val_loss: 1.6783 - val_accuracy: 0.5839\n",
      "Epoch 200/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1925 - accuracy: 0.9578 - val_loss: 1.6815 - val_accuracy: 0.5772\n",
      "Epoch 201/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1921 - accuracy: 0.9628 - val_loss: 1.6822 - val_accuracy: 0.5839\n",
      "Epoch 202/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.1874 - accuracy: 0.9578 - val_loss: 1.7202 - val_accuracy: 0.5839\n",
      "Epoch 203/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.1873 - accuracy: 0.9611 - val_loss: 1.6859 - val_accuracy: 0.5772\n",
      "Epoch 204/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.1854 - accuracy: 0.9645 - val_loss: 1.6980 - val_accuracy: 0.5839\n",
      "Epoch 205/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9611 - val_loss: 1.6905 - val_accuracy: 0.5839\n",
      "Epoch 206/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1862 - accuracy: 0.9628 - val_loss: 1.6919 - val_accuracy: 0.5839\n",
      "Epoch 207/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.9628 - val_loss: 1.6950 - val_accuracy: 0.5839\n",
      "Epoch 208/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1800 - accuracy: 0.9628 - val_loss: 1.7186 - val_accuracy: 0.5839\n",
      "Epoch 209/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1774 - accuracy: 0.9662 - val_loss: 1.7132 - val_accuracy: 0.5772\n",
      "Epoch 210/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.9628 - val_loss: 1.7271 - val_accuracy: 0.5839\n",
      "Epoch 211/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1732 - accuracy: 0.9611 - val_loss: 1.6963 - val_accuracy: 0.5906\n",
      "Epoch 212/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1740 - accuracy: 0.9611 - val_loss: 1.7459 - val_accuracy: 0.5772\n",
      "Epoch 213/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1695 - accuracy: 0.9679 - val_loss: 1.7527 - val_accuracy: 0.5839\n",
      "Epoch 214/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.9628 - val_loss: 1.7340 - val_accuracy: 0.5839\n",
      "Epoch 215/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1657 - accuracy: 0.9696 - val_loss: 1.7267 - val_accuracy: 0.5839\n",
      "Epoch 216/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1664 - accuracy: 0.9628 - val_loss: 1.7354 - val_accuracy: 0.5973\n",
      "Epoch 217/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1636 - accuracy: 0.9713 - val_loss: 1.7603 - val_accuracy: 0.5839\n",
      "Epoch 218/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9628 - val_loss: 1.7530 - val_accuracy: 0.5839\n",
      "Epoch 219/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1590 - accuracy: 0.9696 - val_loss: 1.7378 - val_accuracy: 0.5906\n",
      "Epoch 220/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.9645 - val_loss: 1.7660 - val_accuracy: 0.5906\n",
      "Epoch 221/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1588 - accuracy: 0.9713 - val_loss: 1.7439 - val_accuracy: 0.5839\n",
      "Epoch 222/250\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.1596 - accuracy: 0.9662 - val_loss: 1.7535 - val_accuracy: 0.5973\n",
      "Epoch 223/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9679 - val_loss: 1.7813 - val_accuracy: 0.5906\n",
      "Epoch 224/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1555 - accuracy: 0.9730 - val_loss: 1.7739 - val_accuracy: 0.5906\n",
      "Epoch 225/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9645 - val_loss: 1.7820 - val_accuracy: 0.5839\n",
      "Epoch 226/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9679 - val_loss: 1.7714 - val_accuracy: 0.5839\n",
      "Epoch 227/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9611 - val_loss: 1.7749 - val_accuracy: 0.5973\n",
      "Epoch 228/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9696 - val_loss: 1.7813 - val_accuracy: 0.5906\n",
      "Epoch 229/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9730 - val_loss: 1.7844 - val_accuracy: 0.5839\n",
      "Epoch 230/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9696 - val_loss: 1.7942 - val_accuracy: 0.5839\n",
      "Epoch 231/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9747 - val_loss: 1.7938 - val_accuracy: 0.5839\n",
      "Epoch 232/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9696 - val_loss: 1.8007 - val_accuracy: 0.5772\n",
      "Epoch 233/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9713 - val_loss: 1.8047 - val_accuracy: 0.5906\n",
      "Epoch 234/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9713 - val_loss: 1.7848 - val_accuracy: 0.5906\n",
      "Epoch 235/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1409 - accuracy: 0.9696 - val_loss: 1.7961 - val_accuracy: 0.5906\n",
      "Epoch 236/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1399 - accuracy: 0.9730 - val_loss: 1.8362 - val_accuracy: 0.5906\n",
      "Epoch 237/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 0.9713 - val_loss: 1.8124 - val_accuracy: 0.6040\n",
      "Epoch 238/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1353 - accuracy: 0.9713 - val_loss: 1.8225 - val_accuracy: 0.5839\n",
      "Epoch 239/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9747 - val_loss: 1.8664 - val_accuracy: 0.5973\n",
      "Epoch 240/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1352 - accuracy: 0.9730 - val_loss: 1.8297 - val_accuracy: 0.5906\n",
      "Epoch 241/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9713 - val_loss: 1.8510 - val_accuracy: 0.5839\n",
      "Epoch 242/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.9730 - val_loss: 1.8638 - val_accuracy: 0.5839\n",
      "Epoch 243/250\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1323 - accuracy: 0.9764 - val_loss: 1.8563 - val_accuracy: 0.5973\n",
      "Epoch 244/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1306 - accuracy: 0.9730 - val_loss: 1.8537 - val_accuracy: 0.5973\n",
      "Epoch 245/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9730 - val_loss: 1.8472 - val_accuracy: 0.5973\n",
      "Epoch 246/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1281 - accuracy: 0.9730 - val_loss: 1.8507 - val_accuracy: 0.6040\n",
      "Epoch 247/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1274 - accuracy: 0.9747 - val_loss: 1.8646 - val_accuracy: 0.5906\n",
      "Epoch 248/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1239 - accuracy: 0.9730 - val_loss: 1.8712 - val_accuracy: 0.5906\n",
      "Epoch 249/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1230 - accuracy: 0.9730 - val_loss: 1.8682 - val_accuracy: 0.5839\n",
      "Epoch 250/250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1224 - accuracy: 0.9797 - val_loss: 1.8752 - val_accuracy: 0.6040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f0d43bc10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(100,), activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(54, activation='softmax'))\n",
    "model.compile(optimizer=Adam(0.0002, 0.5), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train_pca,Y_train_encoded,epochs=250,batch_size=32,validation_split=0.2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6cc2119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8455 - accuracy: 0.6541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.845536708831787, 0.6540880799293518)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = model.evaluate(X_test_pca,Y_test_encoded)\n",
    "loss,acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
