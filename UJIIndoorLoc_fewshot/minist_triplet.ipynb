{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b5e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d424d23",
   "metadata": {},
   "source": [
    "### 定义loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de2d3cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于网络结构中将x_a，x_p，x_n直接拼接在了一起，所以使用了下标进行分割。在triplet loss中不需要使用y_true的值\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.4):\n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "    anchor = y_pred[:,0:int(total_lenght*1/3)]\n",
    "    positive = y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    " \n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    " \n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    " \n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e78df",
   "metadata": {},
   "source": [
    "### 样本对的构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec11a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triple(x_train,y_train):\n",
    "    x_anchors=[]\n",
    "    x_positives=[]\n",
    "    x_negatives=[]\n",
    "    for i in range(0, x_train.shape[0]):\n",
    "        #随机选择一个样本x\n",
    "        random_index = random.randint(0, x_train.shape[0] - 1)\n",
    "        x_anchor = x_train[random_index]\n",
    "        y = y_train[random_index]\n",
    "        \n",
    "        #随机选择一个与x相同类型的样本x+\n",
    "        indices_for_pos = np.squeeze(np.where(y_train == y))\n",
    "        x_positive = x_train[indices_for_pos[random.randint(0, len(indices_for_pos) - 1)]]\n",
    "        \n",
    "        #随机选择一个与x不同同类型的样本x-\n",
    "        indices_for_neg = np.squeeze(np.where(y_train != y))\n",
    "        x_negative = x_train[indices_for_neg[random.randint(0, len(indices_for_neg) - 1)]]\n",
    "        \n",
    "        x_anchors.append(x_anchor)\n",
    "        x_positives.append(x_positive)\n",
    "        x_negatives.append(x_negative)\n",
    "        \n",
    "    return np.array(x_anchors), np.array(x_positives), np.array(x_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a9089e",
   "metadata": {},
   "source": [
    "### 特征提取网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254137b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    base_num=16\n",
    "    In1 = layers.Input((28,28,1))\n",
    "    x=layers.Conv2D(8, (3, 3), padding='same', activation='relu')(In1)\n",
    "    x=layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x=layers.Conv2D(8, (3, 3), padding='same', activation='relu')(x)\n",
    "    x=layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x=layers.Conv2D(8, (3, 3), padding='same', activation='relu')(x)\n",
    "    x=layers.Conv2D(base_num, (3, 3), padding='same', activation='relu')(x)\n",
    "    x=layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x=layers.Conv2D(base_num*2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x=layers.Flatten()(x)\n",
    "    x = layers.Dense(40, activation='relu')(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(4, activation='relu')(x)\n",
    "    return Model(In1, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946388f6",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530058d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1,28,28,1).astype('float32')\n",
    "x_test = x_test.reshape(-1,28,28,1).astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "input_shape = x_train.shape[1:]\n",
    " \n",
    "train_a_pairs,train_p_pairs,train_n_pairs=create_triple(x_train,y_train)\n",
    "test_a_pairs,test_p_pairs,test_n_pairs=create_triple(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b184849",
   "metadata": {},
   "source": [
    "### 构建网络和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0620f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network = create_base_network(input_shape)\n",
    " \n",
    "input_a = layers.Input(shape=input_shape)\n",
    "input_p = layers.Input(shape=input_shape)\n",
    "input_n = layers.Input(shape=input_shape)\n",
    " \n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_p = base_network(input_p)\n",
    "processed_n = base_network(input_n)\n",
    "merged_vector = layers.concatenate([processed_a, processed_p, processed_n], axis=-1, name='merged_layer')\n",
    "model = Model([input_a,input_p, input_n], merged_vector)\n",
    "keras.utils.plot_model(model,\"triplet_Model.png\",show_shapes=True)\n",
    "model.summary()\n",
    " \n",
    "# train\n",
    "rms = RMSprop()\n",
    "model.compile(loss=triplet_loss, optimizer=rms)\n",
    "tr_y = np.empty((train_a_pairs.shape[0],1))\n",
    "te_y = np.empty((test_a_pairs.shape[0],1))\n",
    "history=model.fit([train_a_pairs,train_p_pairs,train_n_pairs], tr_y,\n",
    "          batch_size=128,\n",
    "          epochs=20,verbose=2,\n",
    "          validation_data=([test_a_pairs,test_p_pairs,test_n_pairs], te_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e6890",
   "metadata": {},
   "source": [
    "### 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from sklearn.manifold import TSNE\n",
    "# Define our own plot function\n",
    "def scatter(x, labels, subtitle=None):\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", 10))\n",
    " \n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[labels.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    " \n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    for i in range(10):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(x[labels == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "        \n",
    "    if subtitle != None:\n",
    "        plt.suptitle(subtitle)\n",
    "        \n",
    "    plt.savefig(subtitle)\n",
    "tsne = TSNE()\n",
    "X_train_trm = base_network.predict(x_train[:512].reshape(-1,28,28,1))\n",
    "X_test_trm = base_network.predict(x_test[:512].reshape(-1,28,28,1))\n",
    "train_tsne_embeds = tsne.fit_transform(X_train_trm)\n",
    "eval_tsne_embeds = tsne.fit_transform(X_test_trm)\n",
    "scatter(train_tsne_embeds, y_train[:512], \"Training Data After TNN\")\n",
    "scatter(eval_tsne_embeds, y_test[:512], \"Validation Data After TNN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
