{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ce09e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Flatten,concatenate,Dense,Lambda,Dropout\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c17eb",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78e41906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1059, 531)\n",
      "(1059, 130)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        ...,\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110],\n",
       "        [-110, -110, -110, ..., -110, -110, -110]], dtype=int64),\n",
       " array([ 0,  0,  0, ..., 53, 53, 53]),\n",
       " (1059, 119))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./UJIIndoorLoc/children_13/sorted/00_sorted.csv\"\n",
    "train_df = pd.read_csv(path,header=0)\n",
    "print(train_df.shape)\n",
    "a = train_df.mean()\n",
    "a[\"WAP004\"]\n",
    "for i in train_df.columns[:520]:\n",
    "    if a[i]==-110:\n",
    "        del train_df[i]\n",
    "print(train_df.shape)\n",
    "train_df[\"REF\"] = pd.factorize(train_df[\"REF\"])[0].astype(int)#将标签映射到顺序数字上\n",
    "labels = train_df.REF.values\n",
    "features = train_df.drop(columns=['TIMESTAMP','PHONEID','USERID','RELATIVEPOSITION',\n",
    "                                'SPACEID','BUILDINGID','FLOOR','LATITUDE','LONGITUDE',\n",
    "                                'BF','REF']).values\n",
    "features,labels,features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65b35dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12, 20, 51, 15, 41, 48, 37, 11, 33, 21, 27, 46, 31,  5, 30, 13, 41,\n",
       "        43, 29, 28, 21,  9, 28, 46, 29, 12, 39, 47, 49, 27, 25, 47, 40, 53,\n",
       "        42, 12, 39, 52, 22, 36,  2, 41, 26,  5, 31,  5, 35, 35, 30, 51, 42,\n",
       "        26, 36, 51,  0, 31, 34, 38, 28, 50, 14,  2, 33, 36, 41, 33, 49, 25,\n",
       "        52, 15, 25, 12, 26, 29, 37, 51, 52, 29,  9, 11, 50, 53, 35, 47, 14,\n",
       "        42, 22, 20, 13, 44, 15, 13, 30, 36, 45,  7, 16, 47,  7,  8, 32, 52,\n",
       "        15, 29, 28,  0, 50, 36,  5, 40, 20, 32, 13, 49, 35, 13,  9, 47, 27,\n",
       "        41,  5, 18, 12, 41, 24, 24, 38, 19, 24, 46, 50, 48, 23, 50, 41, 23,\n",
       "        43, 45, 13,  6, 33,  6,  1, 17, 53, 38, 21, 15, 13, 47, 26,  6,  0,\n",
       "        25, 26, 34, 39, 22, 18, 25, 51, 35, 35, 51,  6, 12,  7, 23, 29, 14,\n",
       "        34, 36, 51,  1, 29,  3, 51, 20, 39, 36,  9, 48, 46, 33,  6, 20, 20,\n",
       "        36, 39, 15,  4, 47, 25, 37, 26,  4,  0, 10,  0, 17,  5, 14, 15,  8,\n",
       "        48, 11, 49, 26, 13, 16, 20,  7, 34, 31, 20, 24, 36, 13,  5, 12, 20,\n",
       "         7, 20, 27, 25, 19, 22, 30, 17, 31,  6, 47, 29, 27, 29, 20, 52,  4,\n",
       "         8, 17, 33, 35,  5, 13, 26, 14,  6, 47, 22, 35, 33, 20, 14, 43, 13,\n",
       "        44,  9, 53, 13,  8, 34, 25, 20, 11, 42,  2, 38, 27, 50, 40, 53,  4,\n",
       "        40,  5, 41, 39, 41, 25, 48,  9, 52, 30, 49,  2, 31, 13, 48, 35, 14,\n",
       "        12, 29, 47,  4, 25, 32, 49, 13, 16,  0, 28,  3, 39, 32,  5, 33, 10,\n",
       "         6, 42, 17, 19, 16, 21,  5, 13,  7, 48, 12,  9,  5, 41, 13, 41, 26,\n",
       "        25, 38, 27, 18, 46, 30, 18, 44, 19, 36, 29, 17, 13, 31, 26, 18, 33,\n",
       "        37, 32,  0, 45, 18, 37, 27,  0, 19, 12, 38, 29, 50,  4, 36, 17, 44,\n",
       "         2, 46, 24, 38,  4,  0, 50,  4, 37, 37, 25, 37, 16, 14, 48, 13, 16,\n",
       "        11, 15,  1,  8, 31, 25,  8, 16, 10, 50, 52, 23, 51, 38, 10, 10, 24,\n",
       "        42, 14, 11, 32, 49,  4, 16, 30,  6, 47, 50, 27, 40, 10, 34, 26, 49,\n",
       "        42, 33, 41, 45, 51, 32, 10, 53, 25, 16, 37, 14,  7, 30, 32, 15, 27,\n",
       "        11, 42, 13, 17, 17, 11, 21, 12, 21, 26,  0,  2, 32, 21, 12, 20, 13,\n",
       "        46, 33, 18, 34, 53, 51, 13,  7,  4, 13,  1, 53, 22, 24, 25,  1, 44,\n",
       "        40, 13, 40, 23, 28, 38, 37,  0, 42, 27, 33, 19, 25, 46, 52, 32, 31,\n",
       "        49, 13, 34, 26, 48, 28, 11, 39, 13, 53, 30, 46, 37, 25, 12, 19, 49,\n",
       "        43, 53,  7, 42,  4,  6, 13, 28, 47, 49, 14, 46,  6, 31, 15, 33, 50,\n",
       "        12, 22, 46, 20, 45,  3, 20, 40, 19,  0, 18, 31, 22, 25, 31, 46, 41,\n",
       "        47, 52, 34, 25,  4, 43, 19, 23, 22, 12, 25, 41, 42, 50, 17, 21, 14,\n",
       "        21, 11, 40,  7, 38, 13, 23,  4, 30, 34, 26, 34, 22, 47, 45, 27, 40,\n",
       "        17, 34, 15, 42, 44, 26,  5, 44, 39, 21, 24, 43, 51, 16,  3, 26, 22,\n",
       "        35, 21, 13, 27, 51, 44, 40,  6, 44, 37, 20, 51, 12,  3, 22, 49, 48,\n",
       "        33, 39, 51,  1, 30,  8, 14, 45, 45,  9, 29, 35, 38, 42, 19, 32, 45,\n",
       "        35, 39, 18,  1, 12, 18, 37, 45, 48, 21,  6, 50, 44, 16, 52, 52, 28,\n",
       "        46, 16,  8, 38, 45, 49,  0, 17, 34, 20,  5, 24, 46, 40, 25, 13, 34,\n",
       "        30, 44, 28, 15, 29, 32,  8, 14, 35, 24, 21, 35, 21, 15,  7,  9, 18,\n",
       "        19, 32, 45, 37, 18,  3, 19, 38, 22, 53, 27, 50, 43, 26, 52, 53,  8,\n",
       "         8, 30, 17, 24, 30, 20, 44,  4, 45, 19, 52, 26, 24, 45, 39, 11, 44,\n",
       "        31, 28, 42, 28, 36,  0, 15,  7, 16,  3, 39, 44, 53, 16, 36,  7, 26,\n",
       "        38, 12, 26, 28, 51, 48,  2, 40, 39, 36, 53, 22, 31, 28, 18, 40, 15,\n",
       "        20, 49, 24, 26, 13, 24, 48, 32,  6, 52]),\n",
       " array([24,  6,  5, 18, 41, 14, 18, 50,  4, 37, 31,  4, 20, 53, 50, 28, 52,\n",
       "        18, 20, 25, 37, 52,  6, 40,  7, 14, 32, 33, 25, 29, 30, 48, 44, 15,\n",
       "        13, 42, 45, 20, 50, 53, 26, 36, 37, 22, 16, 47, 36, 15, 20,  4, 22,\n",
       "        16, 41, 21, 26, 28,  5, 32, 31, 21, 28, 35, 38, 24, 34,  0, 16, 44,\n",
       "        21, 23, 51, 24, 27, 52, 31, 49, 52, 32, 12, 22, 53, 13, 13, 20, 14,\n",
       "        43, 20, 30, 13, 46, 26, 19, 21, 35, 24,  1, 11, 41, 16,  7,  0, 10,\n",
       "        35, 33, 34, 25, 41,  7, 47,  3, 40, 40, 17, 47,  8, 44, 46,  5, 12,\n",
       "        18, 30, 19,  8, 25, 48, 41, 49, 13, 25,  5, 28, 30, 35, 21, 12,  7,\n",
       "        16, 29, 13, 24, 20,  7, 34, 17, 14, 47,  6, 11,  5, 22, 37, 45, 36,\n",
       "        35, 10, 25, 29,  6, 17, 19, 11, 13, 42, 31, 36, 29, 42, 29, 48, 37,\n",
       "        39, 53, 29, 28,  8,  9,  2,  9, 17, 45, 38, 51, 34, 20,  0, 10, 48,\n",
       "         9, 44, 52, 34, 28, 37, 33, 51, 15,  2, 43,  6,  8, 26, 17, 53, 44,\n",
       "        50, 49, 39, 34, 19, 33, 35, 30, 47, 32, 15,  4,  8, 36, 33, 25, 27,\n",
       "        36, 15, 14, 17, 11, 14, 25, 39, 38, 53, 27, 42, 47,  3, 12, 12, 11,\n",
       "        46,  0,  2, 45, 38, 39, 23, 39, 52,  1, 46, 27, 26, 31, 45,  3, 51,\n",
       "        41,  7, 49, 27, 21, 26,  1,  0, 38, 18,  4, 25, 38,  6, 27, 42, 13,\n",
       "        51, 19, 51, 26, 50, 24, 49, 13, 46, 22, 20, 13, 48, 26,  0, 40, 32,\n",
       "        16, 15, 22, 12, 43, 45, 48, 23, 12, 49, 50, 13, 40, 42, 19, 44, 33,\n",
       "        31,  4,  5, 40, 26, 51, 30, 13, 32,  9, 18, 46]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, \n",
    "                                                    labels, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state= 150,\n",
    "                                                    #random_state：可以理解为随机数种子，主要是为了复现结果而设置\n",
    "                                                    stratify=labels)#保证划分的test中的所有标签齐全\n",
    "X_train,Y_train = shuffle(X_train, Y_train)\n",
    "Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5213688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "scale = StandardScaler().fit(X_train)\n",
    "X_train_transform = scale.transform(X_train)\n",
    "X_test_transform = scale.transform(X_test)\n",
    "Y_train_encoded = to_categorical(Y_train)\n",
    "Y_test_encoded = to_categorical(Y_test)\n",
    "input_dim = (119,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b24820",
   "metadata": {},
   "source": [
    "### 定义特征提取网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64c442ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "def featureNet(input_dim):\n",
    "    inp = Input(shape=input_dim ,name = 'ap_feature')\n",
    "    model = Dense(1024,activation='relu')(inp)\n",
    "    model = Dense(512,activation='relu')(model)\n",
    "    model = Dense(256,activation='relu')(model)\n",
    "    output = Dense(119,activation='relu')(model)\n",
    "    return Model(inp,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71edab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c68c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network = featureNet(input_dim)\n",
    "input_a = Input(shape=input_dim)\n",
    "input_b = Input(shape=input_dim)\n",
    "\n",
    "# because we re-use the same instance`base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model(inputs=[input_a, input_b], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57345f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bd7ac5",
   "metadata": {},
   "source": [
    "### 创建正负样本对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "831ad99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(x,digit_indices):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    #这里n是所有类别的样本数目的最小值再减1\n",
    "    n = min([len(digit_indices[d]) for d in range(54)]) - 1\n",
    "    for d in range(54):\n",
    "        for i in range(n):\n",
    "            # 遍历d类的样本，取临近的两个样本为正样本对\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i+1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            # randrange会产生1~9之间的随机数，含1和9\n",
    "            inc = random.randrange(1, 10)\n",
    "            # (d+inc)%10一定不是d，用来保证负样本对的图片绝不会来自同一个类\n",
    "            dn = (d + inc) % 10\n",
    "            # 在d类和dn类中分别取i样本构成负样本对\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            # 添加正负样本标签\n",
    "            labels += [1.0, 0.0] #标签一定使用浮点数，不然会报错\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ad5ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_indices = [np.where(Y_train == i)[0] for i in range(54)]\n",
    "tr_pairs, tr_y = create_pairs(X_train_transform, digit_indices)\n",
    "\n",
    "digit_indices = [np.where(Y_test == i)[0] for i in range(54)]\n",
    "te_pairs, te_y = create_pairs(X_test_transform, digit_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eacea639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, labels):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() < 0.5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "594cdddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.50679351, -0.13210547, -0.15448632, ..., -0.21598904,\n",
       "         -0.03676073, -0.03676073],\n",
       "        [-0.50679351, -0.13210547, -0.15448632, ..., -0.21598904,\n",
       "         -0.03676073, -0.03676073],\n",
       "        [-0.50679351, -0.13210547, -0.15448632, ..., -0.21598904,\n",
       "         -0.03676073, -0.03676073],\n",
       "        ...,\n",
       "        [-0.50679351, -0.13210547, -0.15448632, ..., -0.21598904,\n",
       "         -0.03676073, -0.03676073],\n",
       "        [-0.50679351, -0.13210547, -0.15448632, ..., -0.21598904,\n",
       "         -0.03676073, -0.03676073],\n",
       "        [-0.50679351, -0.13210547, -0.15448632, ..., -0.21598904,\n",
       "         -0.03676073, -0.03676073]]),\n",
       " array([[-0.50679351, -0.13210547, -0.15448632, ..., -0.21598904,\n",
       "         -0.03676073, -0.03676073],\n",
       "        [-0.50679351, -0.13210547, -0.15448632, ..., -0.21598904,\n",
       "         -0.03676073, -0.03676073],\n",
       "        [-0.50679351, -0.13210547, -0.15448632, ..., -0.21598904,\n",
       "         -0.03676073, -0.03676073],\n",
       "        ...,\n",
       "        [-0.50679351, -0.13210547, -0.15448632, ..., -0.21598904,\n",
       "         -0.03676073, -0.03676073],\n",
       "        [-0.50679351, -0.13210547, -0.15448632, ..., -0.21598904,\n",
       "         -0.03676073, -0.03676073],\n",
       "        [-0.50679351, -0.13210547, -0.15448632, ..., -0.21598904,\n",
       "         -0.03676073, -0.03676073]]),\n",
       " array([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0.]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_pairs[:, 0],tr_pairs[:, 1],tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70c69b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 1s 36ms/step - loss: 0.2699 - val_loss: 0.1191\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0858 - val_loss: 0.0902\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0581 - val_loss: 0.0843\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0528 - val_loss: 0.1801\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0791 - val_loss: 0.0754\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0485 - val_loss: 0.0643\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0380 - val_loss: 0.0550\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0307 - val_loss: 0.0973\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0415 - val_loss: 0.0472\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0285 - val_loss: 0.0566\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0281 - val_loss: 0.0573\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0297 - val_loss: 0.0780\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0244 - val_loss: 0.0580\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0203 - val_loss: 0.0673\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0265 - val_loss: 0.0752\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0243 - val_loss: 0.0985\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0177 - val_loss: 0.0874\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0174 - val_loss: 0.0724\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0175 - val_loss: 0.0684\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0187 - val_loss: 0.0513\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0170 - val_loss: 0.0680\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0136 - val_loss: 0.0879\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0225 - val_loss: 0.0495\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0493\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0115 - val_loss: 0.0509\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0133 - val_loss: 0.0749\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0146 - val_loss: 0.0539\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0172 - val_loss: 0.0480\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0129 - val_loss: 0.0712\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0168 - val_loss: 0.0602\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0091 - val_loss: 0.0805\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0140 - val_loss: 0.0560\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0082 - val_loss: 0.0913\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0169 - val_loss: 0.0405\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0099 - val_loss: 0.0502\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0081 - val_loss: 0.0597\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0870\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0103 - val_loss: 0.0577\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0072 - val_loss: 0.0784\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0112 - val_loss: 0.0942\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0094 - val_loss: 0.0583\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0099 - val_loss: 0.0489\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0618\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0083 - val_loss: 0.0673\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0068 - val_loss: 0.0545\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0086 - val_loss: 0.0662\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0066 - val_loss: 0.0680\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.1080\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0147 - val_loss: 0.0639\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0046 - val_loss: 0.0514\n",
      "21/21 [==============================] - 0s 5ms/step\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "* Accuracy on training set: 100.00%\n",
      "* Accuracy on test set: 95.15%\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms)\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y),\n",
    "          batch_size=64,\n",
    "          epochs=50,\n",
    "          verbose=1)\n",
    "\n",
    "# compute final accuracy on training and test sets\n",
    "pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(pred, tr_y)\n",
    "pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(pred, te_y)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
